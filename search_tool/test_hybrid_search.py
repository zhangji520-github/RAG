# 基于原生的Milvus客户端实现对稀疏字段的关键词全文检索 对稠密字段基于向量的相似度检索 对image图片向量字段的相似度检索
import sys
import os
import numpy as np

# 添加项目根目录到Python路径
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from pymilvus import AnnSearchRequest, MilvusClient, DataType
from env_utils import MILVUS_URI
from pymilvus import Function, FunctionType
from llm_utils import openai_embedding
from pymilvus import RRFRanker
def create_collection():
    # 1. 创建一个 Milvus 连接
    client = MilvusClient(uri=MILVUS_URI)
    print("Milvus 数据库连接已建立")
    # 2. 定义schema
    schema = client.create_schema(auto_id=False)
    # Add fields to schema
    schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True, description="product id")
    schema.add_field(field_name="text", datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True, description="raw text of product description")
    schema.add_field(field_name="text_dense", datatype=DataType.FLOAT_VECTOR, dim=1024, description="text dense embedding")
    schema.add_field(field_name="text_sparse", datatype=DataType.SPARSE_FLOAT_VECTOR, description="text sparse embedding auto-generated by the built-in BM25 function")
    schema.add_field(field_name="image_dense", datatype=DataType.FLOAT_VECTOR, dim=512, description="image dense embedding")
    # Add function to schema
    bm25_function = Function(
        name="text_bm25_emb",
        input_field_names=["text"],
        output_field_names=["text_sparse"],
        function_type=FunctionType.BM25,
    )
    schema.add_function(bm25_function)
    # 3. 配置索引
    index_params = client.prepare_index_params()
    # Add indexes 稠密字段
    index_params.add_index(
        field_name="text_dense",
        index_name="text_dense_index",
        index_type="AUTOINDEX",
        metric_type="IP"
    )
    # Add indexes 稀疏字段
    index_params.add_index(
        field_name="text_sparse",
        index_name="text_sparse_index",
        index_type="SPARSE_INVERTED_INDEX",
        metric_type="BM25",
        params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
    )
    # Add indexes 图片字段
    index_params.add_index(
        field_name="image_dense",
        index_name="image_dense_index",
        index_type="AUTOINDEX",
        metric_type="IP"
    )
    # 4. 创建集合
    if client.has_collection("my_hybrid_collection"):
        client.drop_collection("my_hybrid_collection")
        print("已删除现有集合 'my_hybrid_collection'")
    client.create_collection(collection_name="my_hybrid_collection", schema=schema, index_params=index_params)
    print("集合 'my_hybrid_collection' 创建成功")

def insert_data():
    client = MilvusClient(uri=MILVUS_URI)
    
    # 准备文本数据
    texts = [
        "Red cotton t-shirt with round neck",
        "Wireless noise-cancelling over-ear headphones", 
        "Stainless steel water bottle, 500ml"
    ]
    
    # 使用 openai_embedding 生成文本向量
    print("正在生成文本向量...")
    text_embeddings = openai_embedding.embed_documents(texts)
    
    # 随机生成图像向量 (512维)
    print("正在生成随机图像向量...")
    np.random.seed(42)  # 设置随机种子以确保结果可重现
    image_embeddings = [
        np.random.randn(512).tolist(),
        np.random.randn(512).tolist(), 
        np.random.randn(512).tolist()
    ]
    
    data = [
        {
            "id": 0,
            "text": texts[0],
            "text_dense": text_embeddings[0],
            "image_dense": image_embeddings[0]
        },
        {
            "id": 1,
            "text": texts[1], 
            "text_dense": text_embeddings[1],
            "image_dense": image_embeddings[1]
        },
        {
            "id": 2,
            "text": texts[2],
            "text_dense": text_embeddings[2],
            "image_dense": image_embeddings[2]
        }
    ]
    
    print("正在插入数据到Milvus...")
    res = client.insert(
        collection_name="my_hybrid_collection",
        data=data
    )
    print(f"数据插入完成，插入了 {len(data)} 条记录")
    return res

def hybrid_search():
    query_text = "white headphones, quiet and comfortable"
    
    # 使用 openai_embedding 生成查询文本的向量
    print("正在生成查询文本向量...")
    query_dense_vector = openai_embedding.embed_query(query_text)
    
    # 随机生成查询图像向量 (512维)
    np.random.seed(123)  # 设置不同的随机种子
    query_multimodal_vector = np.random.randn(512).tolist()  # 生成一个512维的随机向量并将array数组转换成python列表

    # 1. text semantic search (dense)
    search_params_dense = {
        "data": [query_dense_vector],
        "anns_field": "text_dense",
        "param": {"nprobe": 10},
        "limit": 2,
    }
    request_dense = AnnSearchRequest(**search_params_dense)
    # 2. full-text search (sparse)
    search_params_sparse = {
        "data": [query_text],
        "anns_field": "text_sparse",
        "limit": 2,
        "param": {"drop_ratio_search": 0.2}
    }
    request_sparse = AnnSearchRequest(**search_params_sparse)
    # 3. image semantic search (dense)
    search_params_image = {
        "data": [query_multimodal_vector],
        "anns_field": "image_dense",
        "param": {"nprobe": 10},
        "limit": 2,
    }
    request_image = AnnSearchRequest(**search_params_image)
    reqs = [request_dense, request_sparse, request_image]
    # 4. rank results
    ranker = RRFRanker(100)
    return reqs, ranker

if __name__ == "__main__":

    create_collection()
    insert_data()
    reqs, ranker = hybrid_search()
    client = MilvusClient(uri=MILVUS_URI)
    
    # 并行搜索：在 my_collection 集合的 text_dense、text_sparse 和 image_dense 三个向量字段上，同时发起三种不同的搜索，每种搜索各自返回最相似的 2 个结果，共得到 6 个候选。
    # 最后由 RRFRanker 对这 6 个候选进行重新排序，得到最终的 2 个最相关结果。
    res = client.hybrid_search(
        collection_name="my_hybrid_collection",
        reqs=reqs,
        ranker=ranker,
        limit=2,
    )

    for hits in res:
        print(f"总共找到 {len(hits)} 个结果")
        for hit in hits:
            print(hit)
            print("-----" * 10)

    